{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a995117",
   "metadata": {},
   "source": [
    "## Taller (DetecciÃ³n)\n",
    "- Realizar un modelo para la localizaciÃ³n de objetos (RegresiÃ³n de las coordenadas de los Bounding Box)\n",
    "\n",
    "Pasos:\n",
    "Crear matriz de etiquetas ( )\n",
    "Graficar etiquetas en imÃ¡genes:\n",
    "Las etiquetas estÃ¡n dadas por\n",
    "dos puntos\n",
    "â€¢ Inicial (x_top, y_top)\n",
    "â€¢ Final (x_bottom, y_bottom)\n",
    "Generar Etiquetas:\n",
    "Normalizar por el tamaÃ±o de\n",
    "la imagen, de esta forma el\n",
    "modelo predice valores entre\n",
    "0-1 por cada coordenada\n",
    "[x\n",
    "...\n",
    "w\n",
    ",\n",
    "y...\n",
    "h ]\n",
    "\n",
    "2. Modelo: Extractor de caracterÃ­sticas\n",
    "(Convoluciones) + Cabeza (regresiÃ³n de 4\n",
    "variables)\n",
    "3. Entrenar con funciÃ³n de pÃ©rdida MSE (Mean\n",
    "Squared Error)\n",
    "Leer el archivo en formato COCO\n",
    "(\"bbox\" : [x,y,width,height])\n",
    "2. Implementar una funciÃ³n para\n",
    "calcular el IoU de dos rectÃ¡ngulos\n",
    "3. Determinar los rectÃ¡ngulos con\n",
    "mayor IOU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7fb6ee",
   "metadata": {},
   "source": [
    "Este notebook entrena un modelo basado en `ResNet18` para detectar la ubicaciÃ³n de aviones en imÃ¡genes. Utiliza coordenadas corregidas de los bounding boxes, data augmentation y entrenamiento sobre imÃ¡genes redimensionadas. Se calcula el IoU promedio como mÃ©trica de desempeÃ±o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a162a5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Ruta al archivo ZIP\n",
    "zip_path = 'data/airplanes.zip'\n",
    "\n",
    "# Ruta del directorio de destino\n",
    "extract_to = 'data/airplanes'\n",
    "\n",
    "# Crear el directorio si no existe\n",
    "os.makedirs(extract_to, exist_ok=True)\n",
    "\n",
    "# Descomprimir el ZIP\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to)\n",
    "\n",
    "print(f\"Descomprimido en: {extract_to}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7a307d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# --- SelecciÃ³n dinÃ¡mica del dispositivo ---\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Usando GPU NVIDIA\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Usando GPU Apple Silicon (MPS)\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Usando CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bba0458",
   "metadata": {},
   "source": [
    "1. Leer el archivo de etiquetas\n",
    "\n",
    "El archivo Airplanes.csv tiene la informaciÃ³n de los bounding boxes (en formato COCO: [x, y, width, height]). Empezaremos leyendo ese archivo y asociÃ¡ndolo con las imÃ¡genes correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a73708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Leer el archivo CSV con las etiquetas\n",
    "df = pd.read_csv('data/Airplanes.csv')\n",
    "print(df.columns)\n",
    "\n",
    "# Mostrar algunas filas para entender la estructura\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a80b996",
   "metadata": {},
   "source": [
    " 2. Convertir a formato COCO (x, y, width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cf747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FunciÃ³n para corregir etiquetas (coordenadas)\n",
    "def corners_to_coco(x_top, y_top, x_bottom, y_bottom):\n",
    "    x = x_bottom\n",
    "    y = x_top\n",
    "    width = y_bottom - x_bottom\n",
    "    height = y_top - x_top\n",
    "    return [x, y, width, height]\n",
    "\n",
    "# Recalcular las coordenadas usando la funciÃ³n corregida\n",
    "df[['x', 'y', 'width', 'height']] = df.apply(\n",
    "    lambda row: pd.Series(corners_to_coco(row['x_top'], row['y_top'], row['x_bottom'], row['y_bottom'])),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Coordenadas finales\n",
    "df['x2'] = df['x'] + df['width']\n",
    "df['y2'] = df['y'] + df['height']\n",
    "\n",
    "# Normalizar para entrenamiento\n",
    "IMAGE_WIDTH = 512\n",
    "IMAGE_HEIGHT = 512\n",
    "df['x_norm'] = df['x'] / IMAGE_WIDTH\n",
    "df['y_norm'] = df['y'] / IMAGE_HEIGHT\n",
    "df['x2_norm'] = df['x2'] / IMAGE_WIDTH\n",
    "df['y2_norm'] = df['y2'] / IMAGE_HEIGHT\n",
    "\n",
    "# Vector para regresiÃ³n\n",
    "df['bbox_norm'] = df[['x_norm', 'y_norm', 'x2_norm', 'y2_norm']].values.tolist()\n",
    "\n",
    "# Agregar ruta de imagen\n",
    "df['image_path'] = df['Image'].apply(lambda x: f\"data/airplanes/airplanes/{x}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6492ce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "def show_image_with_box(image_path, x1, y1, x2, y2):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Image not found or cannot be read: {image_path}\")\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img)\n",
    "    plt.gca().add_patch(\n",
    "        plt.Rectangle((x1, y1), x2 - x1, y2 - y1, edgecolor='green', facecolor='none', linewidth=2)\n",
    "    )\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Mostrar la primera imagen\n",
    "row = df.iloc[0]\n",
    "show_image_with_box(row['image_path'], row['x'], row['y'], row['x2'], row['y2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e4101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer la imagen para obtener sus dimensiones\n",
    "img = cv2.imread('data/airplanes/airplanes/image_0004.jpg')\n",
    "height, width = img.shape[:2]\n",
    "print(f\"Ancho: {width}, Alto: {height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787d9b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "class AirplaneDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        image = Image.open(row['image_path']).convert('RGB')\n",
    "        bbox = torch.tensor(row['bbox_norm'], dtype=torch.float32)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, bbox\n",
    "\n",
    "# AumentaciÃ³n y normalizaciÃ³n\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Crear dataset y dataloader\n",
    "dataset = AirplaneDataset(df, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfa7389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "# Modelo con ResNet18 como backbone\n",
    "class ResNetBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # base = resnet18(pretrained=True)\n",
    "        base = resnet18(pretrained=True)\n",
    "        self.features = nn.Sequential(*list(base.children())[:-1])  # quitar capa final\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 4),\n",
    "            nn.Sigmoid()  # Para mantener coordenadas entre 0 y 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.regressor(x)\n",
    "\n",
    "model = ResNetBackbone().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da621d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(box1, box2):\n",
    "    xi1 = max(box1[0], box2[0])\n",
    "    yi1 = max(box1[1], box2[1])\n",
    "    xi2 = min(box1[2], box2[2])\n",
    "    yi2 = min(box1[3], box2[3])\n",
    "    inter_area = max((xi2 - xi1), 0) * max((yi2 - yi1), 0)\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    return inter_area / union_area if union_area != 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f45dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento\n",
    "best_model = None\n",
    "best_iou = 0.0\n",
    "iou_per_epoch = []\n",
    "EPOCHS = 15\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, targets in dataloader:\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    print(f\"ðŸ” Epoch {epoch+1}/{EPOCHS} - Loss promedio: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c2d87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    " \n",
    "# Evaluar IoU en 20 muestras\n",
    "model.eval()\n",
    "ious = []\n",
    "for i in range(20):\n",
    "    image, target = dataset[i]\n",
    "    image = image.unsqueeze(0).to(device)\n",
    "    pred = model(image).detach().cpu().numpy().flatten()\n",
    "    true = target.numpy().flatten()\n",
    "    pred_box = [pred[0]*512, pred[1]*512, pred[2]*512, pred[3]*512]\n",
    "    true_box = [true[0]*512, true[1]*512, true[2]*512, true[3]*512]\n",
    "    ious.append(compute_iou(pred_box, true_box))\n",
    "\n",
    "avg_iou = np.mean(ious)\n",
    "iou_per_epoch.append(avg_iou)\n",
    "print(f\"ðŸ” IoU promedio: {avg_iou:.3f}\")\n",
    "\n",
    "if avg_iou > best_iou:\n",
    "    best_model = copy.deepcopy(model.state_dict())\n",
    "    best_iou = avg_iou\n",
    "    print(\"âœ… Nuevo mejor modelo guardado.\")\n",
    "\n",
    "torch.save(best_model, \"mejor_modelo_bbox.pth\")\n",
    "print(\"ðŸ“¦ Modelo guardado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cd0a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# box verde en la imagen: Ground Truth (bounding box real del aviÃ³n)\n",
    "# box rojo en la imagen: PredicciÃ³n del modelo (bounding box predicha)\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "def visualize_predictions(model, dataset, num_images=5):\n",
    "    model.eval()\n",
    "    indices = random.sample(range(len(dataset)), num_images)\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(20, 5))\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        image, true_bbox = dataset[idx]\n",
    "        image_input = image.unsqueeze(0).to(device)\n",
    "        pred_bbox = model(image_input).detach().cpu().numpy().flatten()\n",
    "        true = [int(x * 512) for x in true_bbox]\n",
    "        pred = [int(x * 512) for x in pred_bbox]\n",
    "        image_path = df.iloc[idx]['image_path']\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        cv2.rectangle(img, (true[0], true[1]), (true[2], true[3]), (0, 255, 0), 2)\n",
    "        cv2.rectangle(img, (pred[0], pred[1]), (pred[2], pred[3]), (255, 0, 0), 2)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f'Img {idx}')\n",
    "        axes[i].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_predictions(model, dataset, num_images=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computerV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
