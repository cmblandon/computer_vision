{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3850307f",
   "metadata": {},
   "source": [
    "# Taller 02: Clasificación Multiclase de Imágenes\n",
    "\n",
    "**Objetivos:**\n",
    "\n",
    "1. Realizar exploración del conjunto de datos\n",
    "2. Extraer características usando un modelo preentrenado (ResNet50)\n",
    "3. Entrenar una cabeza de clasificación usando AutoGluon\n",
    "4. Evaluar el desempeño del modelo\n",
    "\n",
    "**Estructura de directorios:**\n",
    "```\n",
    "data/labelme/\n",
    "    train/\n",
    "        class_1/\n",
    "        class_2/\n",
    "        ...\n",
    "    test/\n",
    "        class_1/\n",
    "        class_2/\n",
    "        ...\n",
    "```\n",
    "Descargar Dataset de https://www.ais.uni-bonn.de/download/datasets.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb18165",
   "metadata": {},
   "source": [
    "## 1. Exploración del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2730cc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup & Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from autogluon.multimodal import MultiModalPredictor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb9c39d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Selección de GPU si está disponible\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = \"mps\"\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "\n",
    "print(\"Using device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c45be4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrayendo dataset en 'data'...\n",
      "Extracción completa.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "\n",
    "archive = \"LabelMe-12-50k.tar.gz\"\n",
    "extract_dir = os.path.join(\"data\")\n",
    "\n",
    "# Crea el directorio \"data\" si no existe\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "# Verifica si ya se extrajeron las carpetas 'train' y 'test'\n",
    "if not (os.path.isdir(os.path.join(extract_dir, \"train\")) and os.path.isdir(os.path.join(extract_dir, \"test\"))):\n",
    "    if not os.path.isfile(archive):\n",
    "        print(\"Por favor, descarga LabelMe-12-50k.tar.gz en el directorio de trabajo.\")\n",
    "    else:\n",
    "        print(\"Extrayendo dataset en 'data'...\")\n",
    "        with tarfile.open(archive, \"r:gz\") as tar:\n",
    "            tar.extractall(path=extract_dir)\n",
    "        print(\"Extracción completa.\")\n",
    "else:\n",
    "    print(\"El dataset ya se encuentra extraído en\", extract_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "045b2ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  class                        path\n",
      "0  0003  data/train/0003/003301.jpg\n",
      "1  0003  data/train/0003/003467.jpg\n",
      "2  0003  data/train/0003/003473.jpg\n",
      "3  0003  data/train/0003/003315.jpg\n",
      "4  0003  data/train/0003/003329.jpg\n",
      "\n",
      "Número de clases : 40\n",
      "Imágenes por clase:\n",
      " class\n",
      "0003    1000\n",
      "0004    1000\n",
      "0000    1000\n",
      "0036    1000\n",
      "0009    1000\n",
      "0031    1000\n",
      "0030    1000\n",
      "0037    1000\n",
      "0008    1000\n",
      "0001    1000\n",
      "0006    1000\n",
      "0039    1000\n",
      "0024    1000\n",
      "0023    1000\n",
      "0015    1000\n",
      "0012    1000\n",
      "0013    1000\n",
      "0014    1000\n",
      "0022    1000\n",
      "0038    1000\n",
      "0007    1000\n",
      "0021    1000\n",
      "0018    1000\n",
      "0032    1000\n",
      "0035    1000\n",
      "0034    1000\n",
      "0033    1000\n",
      "0005    1000\n",
      "0002    1000\n",
      "0020    1000\n",
      "0027    1000\n",
      "0026    1000\n",
      "0011    1000\n",
      "0029    1000\n",
      "0016    1000\n",
      "0028    1000\n",
      "0017    1000\n",
      "0010    1000\n",
      "0019    1000\n",
      "0025    1000\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ROOT = Path(\"data/train\")           # cambia a test para inspeccionar el split de test\n",
    "IMAGE_GLOB_PATTERN = \"*/*.jpg\" \n",
    "image_paths = list(ROOT.glob(IMAGE_GLOB_PATTERN))    # adapta extensión si es .png o similar\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"class\": [p.parent.name for p in image_paths],\n",
    "    \"path\": image_paths\n",
    "})\n",
    "\n",
    "print(df.head())\n",
    "print(\"\\nNúmero de clases :\", df['class'].nunique())\n",
    "print(\"Imágenes por clase:\\n\", df['class'].value_counts())\n",
    "\n",
    "# Distribución\n",
    "plt.figure()\n",
    "df['class'].value_counts().plot(kind='bar')\n",
    "plt.title(\"Distribución de imágenes por clase (train)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6ae4fa5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 40000 Test size: 10000\n"
     ]
    }
   ],
   "source": [
    "# Parse annotation files into DataFrames\n",
    "# Annotation format: human-readable text files (annotation-train.txt, annotation-test.txt) with 12 floats per image + filename prefix ([kaggle.com](https://www.kaggle.com/datasets/dschettler8845/labelme-12-50k?utm_source=chatgpt.com))\n",
    "\n",
    "def load_annotations(split):\n",
    "    # Buscar el archivo de anotaciones dentro del directorio split\n",
    "    ann_file_options = [\n",
    "        os.path.join(extract_dir, split, f\"annotation-{split}.txt\"),\n",
    "        os.path.join(extract_dir, split, \"annotation.txt\")\n",
    "    ]\n",
    "    \n",
    "    ann_file = None\n",
    "    for candidate in ann_file_options:\n",
    "        if os.path.isfile(candidate):\n",
    "            ann_file = candidate\n",
    "            break\n",
    "    if ann_file is None:\n",
    "        raise FileNotFoundError(\n",
    "            f\"No se encontró un archivo de anotaciones válido para el split '{split}' en {os.path.join(extract_dir, split)}.\"\n",
    "        )\n",
    "    \n",
    "    data = []\n",
    "    with open(ann_file) as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            img_name = parts[0] + \".jpg\"\n",
    "            vals = list(map(float, parts[1:]))\n",
    "            label_idx = vals.index(1.0) if 1.0 in vals else 12\n",
    "            # Buscar la imagen en cualquiera de las subcarpetas (por clase) dentro de <extract_dir>/<split>\n",
    "            pattern = os.path.join(extract_dir, split, \"*\", img_name)\n",
    "            matches = glob.glob(pattern)\n",
    "            if not matches:\n",
    "                raise FileNotFoundError(f\"No se encontró la imagen {img_name} en {os.path.join(extract_dir, split)}\")\n",
    "            image_path = matches[0]\n",
    "            data.append({\n",
    "                \"image\": image_path,\n",
    "                \"label\": label_idx\n",
    "            })\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Cargar anotaciones para train y test\n",
    "train_df = load_annotations(\"train\")\n",
    "test_df  = load_annotations(\"test\")\n",
    "print(\"Train size:\", len(train_df), \"Test size:\", len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fb24bd4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "image",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "12322644-5582-4a4b-9d40-aba54e603d82",
       "rows": [
        [
         "0",
         "data/train/0000/000000.jpg",
         "4"
        ],
        [
         "1",
         "data/train/0000/000001.jpg",
         "1"
        ],
        [
         "2",
         "data/train/0000/000002.jpg",
         "2"
        ],
        [
         "3",
         "data/train/0000/000003.jpg",
         "1"
        ],
        [
         "4",
         "data/train/0000/000004.jpg",
         "1"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/train/0000/000000.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/train/0000/000001.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/train/0000/000002.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/train/0000/000003.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/train/0000/000004.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        image  label\n",
       "0  data/train/0000/000000.jpg      4\n",
       "1  data/train/0000/000001.jpg      1\n",
       "2  data/train/0000/000002.jpg      2\n",
       "3  data/train/0000/000003.jpg      1\n",
       "4  data/train/0000/000004.jpg      1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "56d22391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ResNet50 feature extractor\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "weights = ResNet50_Weights.IMAGENET1K_V1\n",
    "resnet = models.resnet50(weights=weights)\n",
    "feature_extractor = nn.Sequential(*list(resnet.children())[:-1]).to(DEVICE).eval()\n",
    "\n",
    "# Custom Dataset to wrap images + transform\n",
    "class ImageFeatureDataset(Dataset):\n",
    "    def __init__(self, df, transform):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.loc[idx]\n",
    "        from PIL import Image\n",
    "        im = Image.open(row['image']).convert('RGB')\n",
    "        im = self.transform(im)\n",
    "        return im, int(row['label']), idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5823b167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 1250/1250 [03:21<00:00,  6.20it/s]\n",
      "Extracting features: 100%|██████████| 313/313 [00:52<00:00,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 2049) (10000, 2049)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract & store features in DataFrame\n",
    "\n",
    "def extract_features(df):\n",
    "    ds = ImageFeatureDataset(df, transform)\n",
    "    loader = DataLoader(ds, batch_size=32, shuffle=False, num_workers=0)\n",
    "    features = np.zeros((len(ds), 2048), dtype=np.float32)\n",
    "    labels = df['label'].values\n",
    "    for images, _, idxs in tqdm(loader, desc=\"Extracting features\"):\n",
    "        images = images.to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            feats = feature_extractor(images).view(images.size(0), -1)\n",
    "        features[idxs.numpy(), :] = feats.cpu().numpy()\n",
    "    # return new DataFrame\n",
    "    feat_df = pd.DataFrame(features, columns=[f\"f{i}\" for i in range(2048)])\n",
    "    feat_df['label'] = labels\n",
    "    return feat_df\n",
    "\n",
    "train_feat_df = extract_features(train_df)\n",
    "test_feat_df  = extract_features(test_df)\n",
    "print(train_feat_df.shape, test_feat_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7c4545a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features saved to TSV.\n"
     ]
    }
   ],
   "source": [
    "# Save feature files (optional)\n",
    "train_feat_df.to_csv(\"data/features_train.tsv\", index=False)\n",
    "test_feat_df.to_csv(\"data/features_test.tsv\", index=False)\n",
    "print(\"Features saved to TSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c1f82174",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.16\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 24.4.0: Fri Apr 11 18:33:47 PDT 2025; root:xnu-11417.101.15~117/RELEASE_ARM64_T6030\n",
      "CPU Count:          11\n",
      "Pytorch Version:    2.5.1\n",
      "CUDA Version:       CUDA is not available\n",
      "Memory Avail:       4.49 GB / 18.00 GB (25.0%)\n",
      "Disk Space Avail:   276.35 GB / 460.43 GB (60.0%)\n",
      "===================================================\n",
      "\n",
      "AutoMM starts to create your model. ✨✨✨\n",
      "\n",
      "To track the learning progress, you can open a terminal and launch Tensorboard:\n",
      "    ```shell\n",
      "    # Assume you have installed tensorboard\n",
      "    tensorboard --logdir /Users/cristianblandon/projects/computerVision/Taller02-clasificacion/automm_labelme_features\n",
      "    ```\n",
      "\n",
      "Seed set to 0\n",
      "GPU Count: 0\n",
      "GPU Count to be Used: 0\n",
      "\n",
      "/opt/anaconda3/envs/autogluon-env/lib/python3.10/site-packages/autogluon/multimodal/utils/environment.py:131: UserWarning: Only CPU is detected in the instance. This may result in slow speed for MultiModalPredictor. Consider using an instance with GPU support.\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name              | Type               | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | model             | NumericalMLP       | 268 K  | train\n",
      "1 | validation_metric | MulticlassAccuracy | 0      | train\n",
      "2 | loss_func         | CrossEntropyLoss   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "268 K     Trainable params\n",
      "0         Non-trainable params\n",
      "268 K     Total params\n",
      "1.072     Total estimated model params size (MB)\n",
      "12        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "512e5b271fb447c6bc1bdbe969b95e32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee72b3d5719240179e41813ffde32adf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "034f750978cf4c93960f8da75e2edb94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 156: 'val_accuracy' reached 0.79230 (best 0.79230), saving model to '/Users/cristianblandon/projects/computerVision/Taller02-clasificacion/automm_labelme_features/epoch=0-step=156.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37321c04b3264b87b8c6fdd6b33698bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 312: 'val_accuracy' reached 0.81950 (best 0.81950), saving model to '/Users/cristianblandon/projects/computerVision/Taller02-clasificacion/automm_labelme_features/epoch=0-step=312.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7edf99a55f8b452abc38af957f4c30e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 469: 'val_accuracy' reached 0.83610 (best 0.83610), saving model to '/Users/cristianblandon/projects/computerVision/Taller02-clasificacion/automm_labelme_features/epoch=1-step=469.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e465347850aa4a20ae0127de1e8966e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 625: 'val_accuracy' reached 0.83320 (best 0.83610), saving model to '/Users/cristianblandon/projects/computerVision/Taller02-clasificacion/automm_labelme_features/epoch=1-step=625.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "422570e2e025453db7e7f8a2bf540070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 782: 'val_accuracy' reached 0.84200 (best 0.84200), saving model to '/Users/cristianblandon/projects/computerVision/Taller02-clasificacion/automm_labelme_features/epoch=2-step=782.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca2a44cba5c640ec8bbf6b8a5bf9e454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 938: 'val_accuracy' reached 0.84940 (best 0.84940), saving model to '/Users/cristianblandon/projects/computerVision/Taller02-clasificacion/automm_labelme_features/epoch=2-step=938.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6350af9c8804b2aa9134c309282c3f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 1095: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "256a1e4ae1874312ac4bff774537f35f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 1251: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd88be8e358b4863ac8d4ec7fff6ff7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 1408: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d34965728017467eb2c7d370fe9aace6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 1564: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f96f22e3d4254b53b2e49234b076be6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 1721: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d543d2ba6dd147cc999b304c4692875a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 1877: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "197d99ecd92a4f7a8e28b08a557b2e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 2034: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af3ff81a9ba416badc856843543d9a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 2190: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "417e85359563450b82b61467a7b6bb5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 2347: 'val_accuracy' reached 0.84170 (best 0.84940), saving model to '/Users/cristianblandon/projects/computerVision/Taller02-clasificacion/automm_labelme_features/epoch=7-step=2347.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b379cb3e086d4c108dd7c0eff5811b18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 2503: 'val_accuracy' was not in top 3\n",
      "Start to fuse 3 checkpoints via the greedy soup algorithm.\n",
      "/opt/anaconda3/envs/autogluon-env/lib/python3.10/site-packages/autogluon/multimodal/learners/base.py:2117: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=torch.device(\"cpu\"))[\"state_dict\"]  # nosec B614\n",
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd27a11029464e73874dddbb23034c29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/autogluon-env/lib/python3.10/site-packages/autogluon/multimodal/utils/checkpoint.py:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(per_path, map_location=torch.device(\"cpu\"))[\"state_dict\"]  # nosec B614\n",
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a05dccfd64a4d16842a99cf3ba67f09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/autogluon-env/lib/python3.10/site-packages/autogluon/multimodal/utils/checkpoint.py:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(per_path, map_location=torch.device(\"cpu\"))[\"state_dict\"]  # nosec B614\n",
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521a2b4a5a9646c2be8a2c996f9325ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/autogluon-env/lib/python3.10/site-packages/autogluon/multimodal/utils/checkpoint.py:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(per_path, map_location=torch.device(\"cpu\"))[\"state_dict\"]  # nosec B614\n",
      "AutoMM has created your model. 🎉🎉🎉\n",
      "\n",
      "To load the model, use the code below:\n",
      "    ```python\n",
      "    from autogluon.multimodal import MultiModalPredictor\n",
      "    predictor = MultiModalPredictor.load(\"/Users/cristianblandon/projects/computerVision/Taller02-clasificacion/automm_labelme_features\")\n",
      "    ```\n",
      "\n",
      "If you are not satisfied with the model, try to increase the training time, \n",
      "adjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\n",
      "or post issues on GitHub (https://github.com/autogluon/autogluon/issues).\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.multimodal.predictor.MultiModalPredictor at 0x178cf98d0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train numerical MLP head in AutoGluon-Multimodal\n",
    "\n",
    "predictor = MultiModalPredictor(\n",
    "    label='label',\n",
    "    problem_type='multiclass',\n",
    "    path='automm_labelme_features',\n",
    "    presets='medium_quality',\n",
    "    pretrained=False  # use only numerical MLP head\n",
    ")\n",
    "predictor.fit(\n",
    "    train_data=train_feat_df,\n",
    "    tuning_data=test_feat_df,\n",
    "    time_limit=1800,\n",
    "    hyperparameters={\n",
    "        'model.names': ['numerical_mlp'],\n",
    "        'env.per_gpu_batch_size': 64,\n",
    "        'optimization.learning_rate': 1e-3,\n",
    "        'optimization.max_epochs': 20\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e8db9ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1177f2a45247f89ab432ca5d060719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'accuracy': 0.8554}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "704c4a67a9874e17bb375fd7ab2a48de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample predictions: 0     1\n",
      "1    12\n",
      "2     1\n",
      "3     1\n",
      "4    12\n",
      "5     1\n",
      "6    12\n",
      "7     3\n",
      "8    12\n",
      "9    12\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Evaluate & Predict\n",
    "results = predictor.evaluate(test_feat_df)\n",
    "print(\"Evaluation results:\", results)\n",
    "preds = predictor.predict(test_feat_df.drop(columns='label'))\n",
    "print(\"Sample predictions:\", preds[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogluon-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
